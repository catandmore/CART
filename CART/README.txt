是时候作出一些解释了：
这些文件都是函数，我对这些函数做一些说明，函数内的注释没有写完全，以后会继续填补
gini：
基尼系数函数，是决策树的cost_function，评价数据分类的纯度（其实我更愿意说是杂度），值域[0,1],0表示数据分得很纯，是完美分类，1表示数据分类很杂，数据完全没有分开。
与基尼系数相关的公式：
proportion = count(class_value) / count(rows)
gini_index = sum(proportion * (1.0 - proportion))

split：
分类函数，通过分类点（属性+阈值）对数据进行分类，属性值小于阈值的数据分到左侧向量组，属性值大于或等于阈值的数据分到右侧向量组

learn：
这个函数与学习关系并不大，但learn函数是构成决策树至关重要的函数，它通过枚举贪婪算法获得当前数据的最优分类点（基尼系数最小），这些分类点构成了决策树的最小单位node，根据learn获得的分类点可以对落入当前node的数据进行当前最优分类

class_value：
类别判定函数，这个函数表面上看上去似乎没用（因为在split中已经把不同类的数据分到了不同的向量组中），但在训练数据分散较为均匀，分类效果不明显时，可以以少数服从多数的方式校准训练数据类别

learn_tree:
学习的核心函数，利用learn函数不断生成新的节点，构成树的结构（最后返回的对象是字典），生成原理在‘决策树生成原理‘中详细解释
